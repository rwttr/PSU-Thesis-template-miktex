@Comment{My Papers}
@INPROCEEDINGS{myfirstcon,
	author={R. {Wongtanawijit} and T. {Kaorapapong}},
	booktitle={2018 15th International Conference on Electrical Engineering / Electronics, Computer, \\Telecommunications and Information Technology (ECTI-CON)},
	title={{Rubber Tapped Path Detection using K-means Color Segmentation and Distance to Boundary Feature}},
	year={2018},
	volume={},
	number={},
	pages={126-129},
	keywords={farming;image colour analysis;image segmentation;pattern clustering;rubber;smart phones;support vector machines;rubber tapped path detection;color segmentation;boundary feature;detection algorithm;Para rubber tree;Heavea brasiliensis;scene images;light-assisted smartphone camera;intensity thresholding;color clustering;signed-derivative distance;average distance;image partial boundary;sample images;tapped line;k-nearest neighbor;Image color analysis;Vegetation;Rubber;Feature extraction;Cameras;Shape;Support vector machines;latex farming;image boundary;linear svm;rubber trees},
	doi={10.1109/ECTICon.2018.8619863},
	ISSN={null},
	month={July},}
@INPROCEEDINGS{mysecondcon,
	author={R. {Wongtanawijit} and T. {Khaorapapong}},
	booktitle={2019 23rd International Computer Science and Engineering Conference (ICSEC)},
	title={{Rubber Tapping Position and Harvesting Cup Detection Using Faster-RCNN with MobileNetV2}},
	year={2019},
	volume={},
	number={},
	pages={335-339},
	keywords={Rubber Tapping;Hevea brasiliensis;Agricultural;Object Detection;RGB-D},
	doi={10.1109/ICSEC47112.2019.8974731},
	ISSN={null},
	month={Oct},}

@Comment{Datasets}
@article{Caesar2016COCOStuffTA,
  title={{COCO-Stuff: Thing and Stuff Classes in Context}},
  author={Holger Caesar and Jasper R. R. Uijlings and Vittorio Ferrari},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2016},
  pages={1209-1218}}
@InProceedings{10.1007/978-3-319-10602-1_48,
	author="Lin, Tsung-Yi
	and Maire, Michael
	and Belongie, Serge
	and Hays, James
	and Perona, Pietro
	and Ramanan, Deva
	and Doll{\'a}r, Piotr
	and Zitnick, C. Lawrence",
	editor="Fleet, David
	and Pajdla, Tomas
	and Schiele, Bernt
	and Tuytelaars, Tinne",
	title={{Microsoft COCO: Common Objects in Context}},
	booktitle="Computer Vision -- ECCV 2014",
	year="2014",
	publisher="Springer International Publishing",
	address="Cham",
	pages="740--755",
	abstract="We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.",
	isbn="978-3-319-10602-1"}
@Article{Everingham2015,
	author="Everingham, Mark
	and Eslami, S. M. Ali
	and Van Gool, Luc
	and Williams, Christopher K. I.
	and Winn, John
	and Zisserman, Andrew",
	title={{The Pascal Visual Object Classes Challenge: A Retrospective}},
	journal="International Journal of Computer Vision",
	year="2015",
	month="Jan",
	day="01",
	volume="111",
	number="1",
	pages="98--136",
	abstract="The Pascal Visual Object Classes (VOC) challenge consists of two components: (i) a publicly available dataset of images together with ground truth annotation and standardised evaluation software; and (ii) an annual competition and workshop. There are five challenges: classification, detection, segmentation, action classification, and person layout. In this paper we provide a review of the challenge from 2008--2012. The paper is intended for two audiences: algorithm designers, researchers who want to see what the state of the art is, as measured by performance on the VOC datasets, along with the limitations and weak points of the current generation of algorithms; and, challenge designers, who want to see what we as organisers have learnt from the process and our recommendations for the organisation of future challenges. To analyse the performance of submitted algorithms on the VOC datasets we introduce a number of novel evaluation methods: a bootstrapping method for determining whether differences in the performance of two algorithms are significant or not; a normalised average precision so that performance can be compared across classes with different proportions of positive instances; a clustering method for visualising the performance across multiple algorithms so that the hard and easy images can be identified; and the use of a joint classifier over the submitted algorithms in order to measure their complementarity and combined performance. We also analyse the community's progress through time using the methods of Hoiem et al. (Proceedings of European Conference on Computer Vision, 2012) to identify the types of occurring errors. We conclude the paper with an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges.",
	issn="1573-1405",
	doi="10.1007/s11263-014-0733-5",
	url="https://doi.org/10.1007/s11263-014-0733-5"}
@Article{Everingham2010,
	author="Everingham, Mark
	and Van Gool, Luc
	and Williams, Christopher K. I.
	and Winn, John
	and Zisserman, Andrew",
	title={{The Pascal Visual Object Classes (VOC) Challenge}},
	journal="International Journal of Computer Vision",
	year="2010",
	month="Jun",
	day="01",
	volume="88",
	number="2",
	pages="303--338",
	abstract="The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.",
	issn="1573-1405",
	doi="10.1007/s11263-009-0275-4",
	url="https://doi.org/10.1007/s11263-009-0275-4"}
@article{Deng2009ImageNetAL,
  title={{ImageNet: A large-scale hierarchical image database}},
  author={Jia Deng and Wei Dong and Richard Socher and Li-Jia Li and Kai Li and Fei-Fei Li},
  journal={2009 IEEE Conference on Computer Vision and Pattern Recognition},
  year={2009},
  pages={248-255}}
@article{OpenImages,
  author = {Alina Kuznetsova and Hassan Rom and Neil Alldrin and Jasper Uijlings and Ivan Krasin and Jordi Pont-Tuset and Shahab Kamali and Stefan Popov and Matteo Malloci and Tom Duerig and Vittorio Ferrari},
  title = {{The Open Images Dataset V4: Unified image classification, object detection, and visual relationship detection at scale}},
  year = {2018},
  journal = {arXiv:1811.00982}}
@inproceedings{Krizhevsky2009LearningML,
  title={{Learning Multiple Layers of Features from Tiny Images}},
  author={Alex Krizhevsky},
  year={2009}}
@article{David2016Pedestrians,
  author    = {David Hall and
               Pietro Perona},
  title     = {{Fine-Grained Classification of Pedestrians in Video: Benchmark and
               State of the Art}},
  journal   = {CoRR},
  volume    = {abs/1605.06177},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.06177},
  archivePrefix = {arXiv},
  eprint    = {1605.06177},
  timestamp = {Wed, 05 Dec 2018 06:42:48 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HallP16},
  bibsource = {dblp computer science bibliography, https://dblp.org}}
@inproceedings{boxy2019,
   title={Boxy Vehicle Detection in Large Images},
   author={Behrendt, Karsten},
   booktitle={Proceedings of the IEEE International Conference on Computer Vision},    year={2019}}

@Comment{Deep CV Detectors}
@inproceedings{Alexnet2012,
  title={ImageNet Classification with Deep Convolutional Neural Networks},
  author={Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
  booktitle={NIPS},
  year={2012}}
@inproceedings{RCNN,
	author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	title = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
	year = {2014},
	isbn = {9781479951185},
	publisher = {IEEE Computer Society},
	address = {USA},
	url = {https://doi.org/10.1109/CVPR.2014.81},
	doi = {10.1109/CVPR.2014.81},
	booktitle = {Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition},
	pages = {580–587},
	numpages = {8},
	series = {CVPR ’14}}
@article{Ren2017,
	archivePrefix = {arXiv},
	author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	month = {jun},
	number = {6},
	pages = {1137--1149},
	title = {{Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}},
	volume = {39},
	year = {2017}}
@inproceedings{Girshick2015,
 author = {Girshick, Ross},
 title = {{Fast R-CNN}},
 booktitle = {Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)},
 series = {ICCV '15},
 year = {2015},
 isbn = {978-1-4673-8391-2},
 pages = {1440--1448},
 numpages = {9},
 doi = {10.1109/ICCV.2015.169},
 acmid = {2920125},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},} 
@article{Girshick2016,
	address = {Washington, DC, USA},
	author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
	month = {jan},
	number = {1},
	pages = {142--158},
	publisher = {IEEE Computer Society},
	title = {{Region-Based Convolutional Networks for Accurate Object Detection and Segmentation}},
	volume = {38},
	year = {2016}}
@inproceedings{Redmon2016,
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {jun},
	pages = {779--788},
	publisher = {IEEE},
	title = {{You Only Look Once: Unified, Real-Time Object Detection}},
	year = {2016}}
@INPROCEEDINGS{yolo9000,
	author={J. {Redmon} and A. {Farhadi}},
	booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	title={{YOLO9000: Better, Faster, Stronger}},
	year={2017},
	volume={},
	number={},
	pages={6517-6525},
	keywords={image classification;object detection;YOLO9000;COCO detection dataset;ImageNet detection task;YOLO detection method;YOLOv2 model;object detection system;PASCAL VOC;object classification;ImageNet classification dataset;Image resolution;Feature extraction;Training;Real-time systems;Object detection;Detectors},
	doi={10.1109/CVPR.2017.690},
	ISSN={1063-6919},
	month={July},}

@article{RFCN,
  author    = {Jifeng Dai and
               Yi Li and
               Kaiming He and
               Jian Sun},
  title     = {{R-FCN: Object Detection via Region-based Fully Convolutional Networks}},
  journal   = {CoRR},
  volume    = {abs/1605.06409},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.06409},
  archivePrefix = {arXiv},
  eprint    = {1605.06409},
  timestamp = {Mon, 13 Aug 2018 16:46:21 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/DaiLHS16},
  bibsource = {dblp computer science bibliography, https://dblp.org}}
@article{SSD,
  author    = {Wei Liu and
               Dragomir Anguelov and
               Dumitru Erhan and
               Christian Szegedy and
               Scott E. Reed and
               Cheng{-}Yang Fu and
               Alexander C. Berg},
  title     = {{SSD: Single Shot MultiBox Detector}},
  journal   = {CoRR},
  volume    = {abs/1512.02325},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.02325},
  archivePrefix = {arXiv},
  eprint    = {1512.02325},
  timestamp = {Mon, 13 Aug 2018 16:48:29 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LiuAESR15},
  bibsource = {dblp computer science bibliography, https://dblp.org}}
@inproceedings{NMS,
 author = {Neubeck, Alexander and Van Gool, Luc},
 title = {{Efficient Non-Maximum Suppression}},
 year = {2006},
 isbn = {0769525210},
 publisher = {IEEE Computer Society},
 address = {USA},
 url = {https://doi.org/10.1109/ICPR.2006.479},
 doi = {10.1109/ICPR.2006.479},
 booktitle = {Proceedings of the 18th International Conference on Pattern Recognition - Volume 03},
 pages = {850–855},
 numpages = {6},
 series = {ICPR ’06}}
@article{Huang2016SpeedAccuracyTF,
  title={{Speed/Accuracy Trade-Offs for Modern Convolutional Object Detectors}},
  author={Jonathan Huang and Vivek Rathod and Chen Sun and Menglong Zhu and Anoop Korattikara Balan and Alireza Fathi and Ian Fischer and Zbigniew Wojna and Yang Song and Sergio Guadarrama and Kevin Murphy},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={3296-3297}}

@Comment{Pretrained Nets}
@article{mobilenetv1,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {{MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications}},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Mon, 13 Aug 2018 16:46:35 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}}
@article{mobilenetv2,
  author    = {Mark Sandler and
               Andrew G. Howard and
               Menglong Zhu and
               Andrey Zhmoginov and
               Liang{-}Chieh Chen},
  title     = {{Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification,
               Detection and Segmentation}},
  journal   = {CoRR},
  volume    = {abs/1801.04381},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.04381},
  archivePrefix = {arXiv},
  eprint    = {1801.04381},
  timestamp = {Mon, 13 Aug 2018 16:48:30 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-04381},
  bibsource = {dblp computer science bibliography, https://dblp.org}}
@article{resnet,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {{Deep Residual Learning for Image Recognition}},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}}
@article{Bianco2018BenchmarkAO,
  title={Benchmark Analysis of Representative Deep Neural Network Architectures},
  author={Simone Bianco and R{\'e}mi Cad{\`e}ne and Luigi Celona and Paolo Napoletano},
  journal={IEEE Access},
  year={2018},
  volume={6},
  pages={64270-64277}}

@Comment{Image Annotations Tools}
@Article{Labelme,
	author="Russell, Bryan C.
	and Torralba, Antonio
	and Murphy, Kevin P.
	and Freeman, William T.",
	title={{LabelMe: A Database and Web-Based Tool for Image Annotation}},
	journal="International Journal of Computer Vision",
	year="2008",
	month="May",
	day="01",
	volume="77",
	number="1",
	pages="157--173",
	abstract="We seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.",
	issn="1573-1405",
	doi="10.1007/s11263-007-0090-8",
	url="https://doi.org/10.1007/s11263-007-0090-8"}
@misc{LabelImg,
  author = {Tzutalin},
  title = {{LabelImg}},
  year = {2015},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tzutalin/labelImg}},}
@misc{VoTT,
  author = {Microsoft},
  title = {{Visual Object Tagging Tool (VoTT): An electron app for building end to end Object Detection Models from Images and Videos.}},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/microsoft/VoTT}},}

@Comment{RealSense}
@misc{intelrealsense_2019, 
	title={{IntelRealSense/librealsense}}, 
	url={https://github.com/IntelRealSense/librealsense}, 
	journal={GitHub}, author={IntelRealSense}, 
	year={2019}, 
	month={Jun}}
@techreport{Grunnet-Jepsen2018,
	author = {Grunnet-Jepsen, Anders and Sweetser, John N and Woodfill, John},
	title = {{Best-Known-Methods for Tuning Intel{\textregistered} RealSense™ D400 Depth Cameras for Best Performance}},
	volume = {16},
	year = {2018}}
@inproceedings{keselman2017intel,
  title={{Intel Realsense Stereoscopic Depth Cameras}},
  author={Keselman, Leonid and Iselin Woodfill, John and Grunnet-Jepsen, Anders and Bhowmik, Achintya},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={1--10},
  year={2017}}
@MISC{DatasheetD400s,
   author =       {CCE Tech Pubs - Intel Corp},
   title =        {{Intel® RealSenseTM Camera 400 Series (DS5) Product Family Datasheet}},
   editor =       {Surfline.com},
   month =        {January},
   year =         {2019},
   url = {https://www.intel.com/content/dam/support/us/en/documents/emerging-technologies/intel-realsense-technology/Intel-RealSense-D400-Series-Datasheet.pdf},
   note =         {[Online]}, }
@MISC{CADD400s,
   author =       {Intel Corp},
   title =        {{Production CAD Files for Intel® RealSense™ D400 Series}},
   editor =       {intel.com},
   month =        {December},
   year =         {2018},
   url = {https://www.intel.com/content/www/us/en/support/articles/000026841/emerging-technologies/intel-realsense-technology.html},
   note =         {[Online]},
 }

@Comment{ Rubber Tapping Docs}
@article{abraham1992tapping_tappingtheory,
  title={{Tapping of Hevea brasiliensis}},
  author={Abraham, PD},
  journal={Natural Rubber},
  pages={263},
  year={1992}}
@article{PThala2014_morningtapping,
 author = {P.Thala and N.Kaewhgam and K.Kumnornaew and K.Satjawattana},
 title = {{Effects of tapping time period and tapping system on latex yield of rubber trees (Hevea brasiliensis) at University of Phayao, Phayao, Thailand}},
 journal = {Khon Kaen Agriculture Journal},
 volume = {Vol.42 SUPPLEMENT 4},
 year = {2014},}
@article{vijayakumar2009revisedNotation,
  title={Revised international notation for latex harvest technology},
  author={Vijayakumar, KR and Gohet, Eric and Thomas, KU and Xiaodi, Wei and Lakshman, Rodrigo and Sopchoke, Pichit and Karunaichamy, KSTK and Mohd Akbar, Said and others},
  year={2009},
  journal = {Journal of Rubber Research},}
@article{nair2010rubber,
  title={Rubber (Hevea brasiliensis)},
  author={Nair, KP Prabhakaran},
  journal={The agronomy and economy of important tree crops of the developing world},
  pages={237--273},
  year={2010},
  publisher={Elsevier London}}
@inproceedings{chambon2014TappingLength,
	author = {Chambon, B{\'{e}}n{\'{e}}dicte and Angthong, Suttipong and Kongmanee, Chaiya and Somboonsuke, Buncha and Mazon, Sophie and Puengcharoen, Akaraya and Martin, Charlotte and Lacote, R{\'{e}}gis},
	title = {{A Comparative Analysis of Smallholders Tapping Practices in Four Rubber Producing Regions of Thailand}},
	year = {2014},
	month = {2},
	volume = {844},
	pages = {34--37},
	booktitle = {Advances in Rubber},
	series = {Advanced Materials Research},
	publisher = {Trans Tech Publications Ltd},
	doi = {10.4028/www.scientific.net/AMR.844.34},
	keywords = {Thailand, Hevea, Small Farms, Tapping Frequency, Tapping Days},
	abstract = {Rubber has been grown for long in the South and East of Thailand. Since 2005, rubber plantations have largely spread to new regions, in the North and above all in the Northeast. Tapping is one of the most important practices to optimize the yield of rubber plantations and farmers income [. If tapping practices are well documented in the traditional growing areas [2, , we lack information for the new rubber producing regions. And so far, no study has been done at the level of the country. Therefore, a survey was conducted with 219 rubber farmers from 10 provinces in four rubber producing regions to describe farmers tapping practices. The objective was to compare farmers practices in the different regions and try to identify some standardization or differentiation factors. Results show that tapping systems used by the farmers vary with the region but everywhere, even in the South and Centre east, the real tapping practices are not really intensive. Tapping practices seem to be linked to farmers rubber experience, the size of mature plantation, the rainfall and the length of the leaf-fall period. So finally, tapping days are irregularly distributed throughout the year which probably affects latex physiology and so, the potential yield of rubber plantations.}}
@article{chantuma2011TappingLength,
  title={An innovative tapping system, the double cut alternative, to improve the yield of Hevea brasiliensis in Thai rubber plantations},
  author={Chantuma, Pisamai and Lacote, R{\'e}gis and Leconte, Antoine and Gohet, Eric},
  journal={Field crops research},
  volume={121},
  number={3},
  pages={416--422},
  year={2011},
  publisher={Elsevier}}
@inproceedings{gohet2016TappingTime,
  title={Improving Rubber Smallholdings Productivity and Resilience through Adoption of Good Agricultural Practices},
  author={Gohet, Eric and Lacote, R{\'e}gis and Leconte, Antoine and Chapuset, Thierry and Rivano, Franck and Chambon, B{\'e}n{\'e}dicte},
  booktitle={Focus Forum on Natural Rubber Sustainability. International Rubber Study Group, Singapore},
  year={2016}}
@article{PETHIN2015Breed251600,
   title = {{Performance and genetic assessment of rubber tree clones in Southern Thailand}},
   journal = {{Scientia Agricola}},
   author={Pethin, Denduang AND Nakkanong, Korakot AND Nualsri, Charassri},
   ISSN = {0103-9016},
   language = {en},
   URL = {http://www.scielo.br/scielo.php?script=sci_arttext&pid=S0103-90162015000400306&nrm=iso},
   volume = {72},
   year = {2015},
   month = {08},
   pages = {306 - 313},
   publisher = {scielo}}
@article{Gohet2003tappingtheory,
	author = {Gohet, Eric and Chantuma, Pisamai},
	journal = {IRRDB annual meeting, 15 - 16 September, Chiang Mai, Thailand},
	title = {{Reduced tapping frequency and DCA tapping systems Research towards improvement of Thailand rubber plantations productivity}},
	year = {2003}}
@article{Simien2011,
	author = {Simien, A. and Penot, Eric},
	year = {2011},
	month = {05},
	pages = {247-260},
	title = {{Current Evolution of Smallholder Rubber-Based Farming Systems in Southern Thailand}},
	volume = {30},
	journal = {Journal of Sustainable Forestry},
	doi = {10.1080/10549811.2011.530936}}

@Comment{Agriculture Robots}
@INPROCEEDINGS{asparagusColorDepth,
	author={N. {Irie} and N. {Taguchi} and T. {Horie} and T. {Ishimatsu}},
	booktitle={2009 IEEE International Conference on Industrial Technology},
	title={Asparagus harvesting robot coordinated with 3-D vision sensor},
	year={2009},
	volume={},
	number={},
	pages={1-6},
	keywords={agriculture;image sensors;robot vision;asparagus harvesting robot;3D vision sensor;robotic arm;drive mechanism;Robot sensing systems;Robot kinematics;Robot vision systems;Robotics and automation;Service robots;Sensor systems;Microcomputers;Mechanical sensors;Agricultural engineering;Navigation},
	doi={10.1109/ICIT.2009.4939556},
	ISSN={null},
	month={Feb},}
@INPROCEEDINGS{grapeRobot,
	author={M. {Monta} and N. {Kondo} and Y. {Shibano}},
	booktitle={Proceedings of 1995 IEEE International Conference on Robotics and Automation},
	title={Agricultural robot in grape production system},
	year={1995},
	volume={3},
	number={},
	pages={2504-2509 vol.3},
	keywords={agriculture;manipulators;materials handling;automation;robot vision;multipurpose agricultural robot;grape production system;vineyard;visual sensor;end-effecters;harvesting;berry thinning;spraying;bagging;Pipelines;Production systems;Robot sensing systems;Robot kinematics;Manipulators;Spraying;Bagging;Management training;Fingers;Wrist},
	doi={10.1109/ROBOT.1995.525635},
	ISSN={1050-4729},
	month={May},}
@article{appleRobot2017,
	author = {Silwal, Abhisesh and Davidson, Joseph R. and Karkee, Manoj and Mo, Changki and Zhang, Qin and Lewis, Karen},
	title = {Design, integration, and field evaluation of a robotic apple harvester},
	journal = {Journal of Field Robotics},
	volume = {34},
	number = {6},
	pages = {1140-1159},
	keywords = {apple, cycle time, machine vision, manipulator, robotic harvesting},
	doi = {10.1002/rob.21715},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21715},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/rob.21715},
	abstract = {Abstract Every apple destined for the fresh market is picked by the human hand. Despite extensive research over the past four decades, there are no mechanical apple harvesters for the fresh market commercially available, which is a significant concern because of increasing uncertainty about the availability of manual labor and rising production costs. The highly unstructured orchard environment has been a major challenge to the development of commercially viable robotic harvesting systems. This paper reports the design and field evaluation of a robotic apple harvester. The approach adopted was to use a low-cost system to assess required sensing, planning, and manipulation functionality in a modern orchard system with a planar canopy. The system was tested in a commercial apple orchard in Washington State. Workspace modifications and performance criteria are thoroughly defined and reported to help evaluate the approach and guide future enhancements. The machine vision system was accurate and had an average localization time of 1.5 s per fruit. The seven degree of freedom harvesting system successfully picked 127 of the 150 fruit attempted for an overall success rate of 84\% with an average picking time of 6.0 s per fruit. Future work will include integration of additional sensing and obstacle detection for improved system robustness.},
	year = {2017}}
@ARTICLE{cucumberRobot2018,
	author={R. {Fernández} and H. {Montes} and J. {Surdilovic} and D. {Surdilovic} and P. {Gonzalez-De-Santos} and M. {Armada}},
	journal={IEEE Access},
	title={Automatic Detection of Field-Grown Cucumbers for Robotic Harvesting},
	year={2018},
	volume={6},
	number={},
	pages={35512-35527},
	keywords={agriculture;data mining;feature extraction;image classification;image segmentation;irrigation;mobile robots;pattern classification;robust control;support vector machines;transforms;Euclidean distance transform;watershed transform;automatic cucumber-harvesting applications;cucumber level;pixel level;ground truth data;cucumber levels;field conditions;minima imposition technique;segmentation procedure;detection reliability;bag-of-visual-words model;image category classifier;support vector machine pixel classifier;classification system;data mining techniques;precision agriculture applications;robotic harvesting automation;robust algorithm;field-grown cucumbers;automatic detection;Robot sensing systems;Greenhouses;Cameras;Classification algorithms;Image segmentation;Robot vision system;precision agriculture;grown-field cucumbers;automatic detection;image processing;robotic harvesting;machine learning;SVM;bag-of-visual-words},
	doi={10.1109/ACCESS.2018.2851376},
	ISSN={2169-3536},
	month={},}
@inproceedings{Lin2019GuavaDA,
  title={Guava Detection and Pose Estimation Using a Low-Cost RGB-D Sensor in the Field},
  author={Guichao Lin and Yunchao Tang and Xiangjun Zou and Juntao Xiong and Jinhui Li},
  booktitle={Sensors},
  year={2019}}
@article{leu2017robotic,
  title={Robotic green asparagus selective harvesting},
  author={Leu, Adrian and Razavi, Mohammad and Langst{\"a}dtler, Lasse and Risti{\'c}-Durrant, Danijela and Raffel, Holger and Schenck, Christian and Gr{\"a}ser, Axel and Kuhfuss, Bernd},
  journal={IEEE/ASME Transactions on Mechatronics},
  volume={22},
  number={6},
  pages={2401--2410},
  year={2017},
  publisher={IEEE}}
@article{silwal2017design,
  title={Design, integration, and field evaluation of a robotic apple harvester},
  author={Silwal, Abhisesh and Davidson, Joseph R and Karkee, Manoj and Mo, Changki and Zhang, Qin and Lewis, Karen},
  journal={Journal of Field Robotics},
  volume={34},
  number={6},
  pages={1140--1159},
  year={2017},
  publisher={Wiley Online Library}}
@article{fernandez2018ColorSpectrum,
  title={Automatic Detection of Field-Grown Cucumbers for Robotic Harvesting},
  author={Fern{\'a}ndez, Roemi and Montes, H{\'e}ctor and Surdilovic, Jelena and Surdilovic, Dragojlub and Gonzalez-De-Santos, Pablo and Armada, Manuel},
  journal={IEEE Access},
  volume={6},
  pages={35512--35527},
  year={2018},
  publisher={IEEE}}

@Comment{Rubber Tapping Robots and Production}
@article{zhang2019rubber,
  title={{A Rubber-Tapping Robot Forest Navigation and Information Collection System Based on 2D LiDAR and a Gyroscope}},
  author={Zhang, Chunlong and Yong, Liyun and Chen, Ying and Zhang, Shunlu and Ge, Luzhen and Wang, Song and Li, Wei},
  journal={Sensors},
  volume={19},
  number={9},
  pages={2136},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}}
@inproceedings{soumya2016design,
  title={Design and testing of a semi automatic rubber tree tapping machine (SART)},
  author={Soumya, Susan John and Vishnu, Rajendran S and Arjun, R Nair and Bhavani, Rao R},
  booktitle={2016 IEEE Region 10 Humanitarian Technology Conference (R10-HTC)},
  pages={1--4},
  year={2016},
  organization={IEEE}}
@inproceedings{susanto2019design,
  title={{The Design of Flexible Rubber Tapping Tool with Settings the Depth and Thickness Control}},
  author={Susanto, H and Ali, S and others},
  booktitle={IOP Conference Series: Materials Science and Engineering},
  volume={506},
  year={2019},
  organization={IOP Publishing}}
@article{Maliackal2017Rail,
	author = {Maliackal, J V C and Asif, K A and Sajith, P A and Joseph, Sajo K},
	journal = {Int. J. Res. Innov. Eng. Sci. Technol.},
	keywords = {cambium layer,cordless drilling machine,mechanisation,rubber latex,rubber tapping},
	number = {5},
	pages = {253--263},
	title = {{Advanced Rubber Tree Tapping Machine}},
	volume = {2},
	year = {2017}}
@article{yatawara2019appuhamy,
  title={{“Appuhamy”-The Fully Automatic Rubber Tapping Machine}},
  author={Yatawara, YAI and Brito, WHC and Perera, MSS and Balasuriya, DN},
  journal={ENGINEER},
  year={2019},
  volume={27},
  pages={1}}
@inproceedings{kunghun2018development,
  title={Development of a Vision Based Mapping in Rubber Tree Orchard},
  author={Kunghun, Worawut and Tantrapiwat, Akapot},
  booktitle={2018 International Conference on Engineering, Applied Sciences, and Technology (ICEAST)},
  pages={1--4},
  year={2018},
  organization={IEEE}}
@Article{tappingKnife2016,
    author    = {Mahathaninwong, N. and Chucheep, T. and Muangdee, N. and Kongtim, P. and Anancharoenwong, A. and Marthosa, S. and Sumangkay, K.},
    title     = {Para rubber tapping behavior, using of para rubber tapping knife behavior and automatic para rubber tapping machine concept evaluation of rubber farmers.},
    journal = {Journal of Agricultural Research and Extension},
    year      =  {2016},
    volume    = {33} ,
    number = {1},
    pages = {66-76}}
@article{coatedCUP,
  title={{COATING LATEX CUP WITH PTFE TO DECREASE LATEX ATTACHMENT}},
  author={Anucha Watanapa, Suthiphong Sopha and Wisitsree Wiyaratn, Predee Pinpradup and Naratip Rawungsook},
  journal={วารสารวิศวกรรมศาสตร์ ปีที่ 2 ฉบับที่ 2 วิศวกรรมเทคโนโลยีไทย},
  volume={2},
  number={9},
  pages={70},
  year={2010},
  publisher={Faculty of Engineering, Chulalongkorn University}}

@Comment{Conventional Image Processing}
@inproceedings{di1999simple,
  title={{A simple and efficient connected components labeling algorithm}},
  author={Di Stefano, Luigi and Bulgarelli, Andrea},
  booktitle={Proceedings 10th International Conference on Image Analysis and Processing},
  pages={322--327},
  year={1999},
  organization={IEEE}}
@InProceedings{10.1007/978-3-642-04146-4_87,
	author="Grana, Costantino
	and Borghesani, Daniele
	and Cucchiara, Rita",
	editor="Foggia, Pasquale
	and Sansone, Carlo
	and Vento, Mario",
	title={{Connected Component Labeling Techniques on Modern Architectures}},
	booktitle="Image Analysis and Processing -- ICIAP 2009",
	year="2009",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="816--824",
	abstract="In this paper we present an overview of the historical evolution of connected component labeling algorithms, and in particular the ones applied on images stored in raster scan order. This brief survey aims at providing a comprehensive comparison of their performance on modern architectures, since the high availability of memory and the presence of caches make some solutions more suitable and fast. Moreover we propose a new strategy for label propagation based on a 2x2 blocks, which allows to improve the performance of many existing algorithms. The tests are conducted on high resolution images obtained from digitized historical manuscripts and a set of transformations is applied in order to show the algorithms behavior at different image resolutions and with a varying number of labels.",
	isbn="978-3-642-04146-4"}
@INPROCEEDINGS{HumanHOG,
	author={N. {Dalal} and B. {Triggs}},
	booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
	title={Histograms of oriented gradients for human detection},
	year={2005},
	volume={1},
	number={},
	pages={886-893 vol. 1},
	keywords={object detection;support vector machines;object recognition;feature extraction;gradient methods;histograms of oriented gradients;human detection;robust visual object recognition;linear SVM;edge based descriptors;gradient based descriptors;fine-scale gradients;fine orientation binning;coarse spatial binning;contrast normalization;overlapping descriptor;pedestrian database;Histograms;Humans;Robustness;Object recognition;Support vector machines;Object detection;Testing;Image edge detection;High performance computing;Image databases},
	doi={10.1109/CVPR.2005.177},
	ISSN={1063-6919},
	month={June},}
@INPROCEEDINGS{GaborFilters, 
	author={A. K. {Jain} and F. {Farrokhnia}}, 
	booktitle={1990 IEEE International Conference on Systems, Man, and Cybernetics Conference Proceedings}, 
	title={{Unsupervised texture segmentation using Gabor filters}}, 
	year={1990}, 
	volume={}, 
	number={}, 
	pages={14-19}, 
		keywords={filtering and prediction theory;pattern recognition;picture processing;statistical analysis;unsupervised texture segmentation;picture processing;pattern recognition;Gabor filters;multichannel filtering theory;spatial-frequency domain;systematic filter selection;unsupervised square-error clustering;spatial adjacency information;statistics;Gabor filters;Channel bank filters;Humans;Clustering algorithms;Filtering algorithms;Filtering theory;Information processing;Visual system;Image reconstruction;Energy measurement}, 
	doi={10.1109/ICSMC.1990.142050}, 
	ISSN={}, 
	month={Nov},}
@article{otsu1979threshold,
  title={{A threshold selection method from gray-level histograms}},
  author={Otsu, Nobuyuki},
  journal={IEEE transactions on systems, man, and cybernetics},
  volume={9},
  number={1},
  pages={62--66},
  year={1979},
  publisher={IEEE}}
@article{huttenlocher1993comparing,
  title={{Comparing images using the Hausdorff distance}},
  author={Huttenlocher, Daniel P and Klanderman, Gregory A and Rucklidge, William J},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={15},
  number={9},
  pages={850--863},
  year={1993},
  publisher={IEEE}}
@article{alt2008computing,
  title={{Computing the Hausdorff distance between curved objects}},
  author={Alt, Helmut and Scharf, Ludmila},
  journal={International Journal of Computational Geometry \& Applications},
  volume={18},
  number={04},
  pages={307--320},
  year={2008},
  publisher={World Scientific}}
@ARTICLE{ContourDetection2011,
	author={P. {Arbeláez} and M. {Maire} and C. {Fowlkes} and J. {Malik}},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	title={{Contour Detection and Hierarchical Image Segmentation}},
	year={2011},
	volume={33},
	number={5},
	pages={898-916},
	keywords={computer vision;edge detection;image segmentation;object detection;pattern clustering;trees (mathematics);contour detection;hierarchical image segmentation;computer vision;spectral clustering;hierarchical region tree;Image segmentation;Pixel;Detectors;Image edge detection;Humans;Histograms;Benchmark testing;Contour detection;image segmentation;computer vision.;Algorithms;Animals;Cluster Analysis;Humans;Image Processing, Computer-Assisted},
	doi={10.1109/TPAMI.2010.161},
	ISSN={1939-3539},
	month={May},}
@article{HaunHumanPerceptions,
    author = {Haun, Andrew M. and Peli, Eli},
    title = "{Perceived contrast in complex images}",
    journal = {Journal of Vision},
    volume = {13},
    number = {13},
    pages = {3-3},
    year = {2013},
    month = {11},
    abstract = "{  To understand how different spatial frequencies contribute to the overall perceived contrast of complex, broadband photographic images, we adapted the classification image paradigm. Using natural images as stimuli, we randomly varied relative contrast amplitude at different spatial frequencies and had human subjects determine which images had higher contrast. Then, we determined how the random variations corresponded with the human judgments. We found that the overall contrast of an image is disproportionately determined by how much contrast is between 1 and 6 c/°, around the peak of the contrast sensitivity function (CSF). We then employed the basic components of contrast psychophysics modeling to show that the CSF alone is not enough to account for our results and that an increase in gain control strength toward low spatial frequencies is necessary. One important consequence of this is that contrast constancy, the apparent independence of suprathreshold perceived contrast and spatial frequency, will not hold during viewing of natural images. We also found that images with darker low-luminance regions tended to be judged as having higher overall contrast, which we interpret as the consequence of darker local backgrounds resulting in higher band-limited contrast response in the visual system. }",
    issn = {1534-7362},
    doi = {10.1167/13.13.3},
    url = {https://doi.org/10.1167/13.13.3},
    eprint = {https://arvojournals.org/arvo/content\_public/journal/jov/933542/i1534-7362-13-13-3.pdf},}
@article{Perona1990DetectingAL,
  title={Detecting and localizing edges composed of steps, peaks and roofs},
  author={Pietro Perona and Jitendra Malik},
  journal={[1990] Proceedings Third International Conference on Computer Vision},
  year={1990},
  pages={52-57}}
@inproceedings{Witkin1983,
	address = {San Francisco, CA, USA},
	author = {Witkin, Andrew P},
	booktitle = {Proceedings of the Eighth International Joint Conference on Artificial Intelligence - Volume 2},
	pages = {1019--1022},
	publisher = {Morgan Kaufmann Publishers Inc.},
	series = {IJCAI'83},
	title = {{Scale-space Filtering}},
	year = {1983}}
@article{dey2019uneven,
  title={Uneven illumination correction of digital images: A survey of the state-of-the-art},
  author={Dey, Nilanjan},
  journal={Optik},
  volume={183},
  pages={483--495},
  year={2019},
  publisher={Elsevier}}
@article{Benhamou2004Straightness,
	author = {Benhamou, Simon},
	year = {2004},
	month = {08},
	pages = {209-20},
	title = {How to reliably estimate the tortuosity of an animal's path: Straightness, sinuosity, or fractal dimension?},
	volume = {229},
	journal = {Journal of theoretical biology},
	doi = {10.1016/j.jtbi.2004.03.016}}
@article{Fujioka2005SmoothingSpline,
	author = {Fujioka, Hiroyuki and Kano, H and Egerstedt, Magnus and Martin, Clyde},
	journal = {Int. J. of Innovative Computing, Information and Control},
	title = {{Smoothing Spline Curves and Surfaces for Sampled Data}},
	volume = {1},
	year = {2005}}
@book{JGreen1994,
	author = {J Green, Peter and Silverman, Bernard},
	year = {1994},
	month = {12},
	pages = {182},
	title = {Nonparametric Regression and Generalized Linear Models: A Roughness Penalty Approach.},
	volume = {50},
	isbn = {9780412300400},
	journal = {Biometrics},
	doi = {10.1007/978-1-4899-4473-3}}
@article{Sural2002RGBHSV,
  title={Segmentation and histogram generation using the HSV color space for image retrieval},
  author={Shamik Sural and Gang Qian and Sakti Pramanik},
  journal={Proceedings. International Conference on Image Processing},
  year={2002},
  volume={2},
  pages={II-II}}
@article{Ibraheem2012ColorReview,
	author = {Ibraheem, Noor and Hasan, Mokhtar and Khan, Rafiqul Zaman and Mishra, Pramod},
	year = {2012},
	month = {01},
	pages = {},
	title = {{Understanding Color Models: A Review}},
	volume = {2},
	journal = {ARPN Journal of Science and Technology}}
@book{ColorSpringerBook,
	author = {Plataniotis, Konstantinos and Venetsanopoulos, A.},
	year = {2000},
	month = {01},
	pages = {},
	title = {Color Image Processing and Applications},
	journal = {Springer Verlag. Berlin},
	doi = {10.1007/978-3-662-04186-4}}
@article{SHou1979CubicSplineUseage,
	author = {{S. Hou}, Hsieh and {C. Andrews}, Harry},
	journal = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
	pages = {508--517},
	title = {{Cubic Splines for Image Interpolation and Digital Filtering}},
	volume = {26},
	year = {1979}}

@Comment{Annotations Problems}
@inproceedings{Hou2013,
	author = {Hou, Xiaodi and Yuille, Alan and Koch, Christof},
	booktitle = {Proceedings / CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	doi = {10.1109/CVPR.2013.276},
	pages = {2123--2130},
	title = {{Boundary Detection Benchmarking: Beyond F-Measures}},
	year = {2013}}
@inproceedings{Martin2001,
	author = {Martin, David and Fowlkes, Charless and Tal, Doron and Malik, Jitendra},
	booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
	pages = {416--423 vol.2},
	title = {{A Database of Human Segmented Natural Images and its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics}},
	volume = {2},
	year = {2001}}

@Comment{Agricultual CV}
@article{kinectApple1,
	author = {Rosell-Polo, Joan and Gregorio Lopez, Eduard and Gené-Mola, Jordi and Llorens Calveras, Jordi and Torrent, Xavier and Arnó, Jaume and Escolà, Alexandre},
	year = {2017},
	month = {02},
	pages = {},
	title = {Kinect v2 Sensor-Based Mobile Terrestrial Laser Scanner for Agricultural Outdoor Applications},
	volume = {In press},
	journal = {IEEE/ASME Transactions on Mechatronics},
	doi = {10.1109/TMECH.2017.2663436}}
@article{kinectApple2,
	author = {Kang, Hanwen and Chen},
	year = {2019},
	month = {10},
	pages = {4599},
	title = {Fruit Detection and Segmentation for Apple Harvesting Using Visual Sensor in Orchards},
	volume = {19},
	journal = {Sensors},
	doi = {10.3390/s19204599}}
@article{liu2016method,
  title={A method of segmenting apples at night based on color and position information},
  author={Liu, Xiaoyang and Zhao, Dean and Jia, Weikuan and Ruan, Chengzhi and Tang, Shuping and Shen, Tian},
  journal={Computers and Electronics in Agriculture},
  volume={122},
  pages={118--123},
  year={2016},
  publisher={Elsevier}}
@INPROCEEDINGS{tomatoCircular,
	author={R. {Xiang} and Y. {Ying} and H. {Jiang}},
	booktitle={2013 6th International Congress on Image and Signal Processing (CISP)},
	title={A recognition algorithm for occluded tomatoes based on circle regression},
	year={2013},
	volume={2},
	number={},
	pages={713-717},
	keywords={agricultural products;edge detection;image segmentation;regression analysis;recognition algorithm;occluded tomatoes;harvesting work automation;fruit automatic recognition;vegetable automatic recognition;edge points;image segmentation;edge recognition;circle regression rules;Image edge detection;Sorting;Image segmentation;Image color analysis;Robots;Machine vision;harvesting robot;tomato;occlusion;recognition;circle regression},
	doi={10.1109/CISP.2013.6745258},
	ISSN={null},
	month={Dec},}
@article{longsheng2015kiwifruit,
  title={Kiwifruit recognition at nighttime using artificial lighting based on machine vision},
  author={Longsheng, Fu and Bin, Wang and Yongjie, Cui and Shuai, Su and Gejima, Yoshinori and Kobayashi, Taiichi},
  journal={International Journal of Agricultural and Biological Engineering},
  volume={8},
  number={4},
  pages={52--59},
  year={2015}}
@article{linker2015apple,
  title={Apple detection in nighttime tree images using the geometry of light patches around highlights},
  author={Linker, Raphael and Kelman, Eliyahu},
  journal={Computers and Electronics in Agriculture},
  volume={114},
  pages={154--162},
  year={2015},
  publisher={Elsevier}}
@article{zhao2016review,
  title={A review of key techniques of vision-based control for harvesting robot},
  author={Zhao, Yuanshen and Gong, Liang and Huang, Yixiang and Liu, Chengliang},
  journal={Computers and Electronics in Agriculture},
  volume={127},
  pages={311--323},
  year={2016},
  publisher={Elsevier}}
@article{hamuda2016survey,
  title={A survey of image processing techniques for plant extraction and segmentation in the field},
  author={Hamuda, Esmael and Glavin, Martin and Jones, Edward},
  journal={Computers and Electronics in Agriculture},
  volume={125},
  pages={184--199},
  year={2016},
  publisher={Elsevier}}
@article{xiang2018image,
  title={Image segmentation for whole tomato plant recognition at night},
  author={Xiang, Rong},
  journal={Computers and Electronics in Agriculture},
  volume={154},
  pages={434--442},
  year={2018},
  publisher={Elsevier}}
@article{gongal2016apple,
  title={Apple crop-load estimation with over-the-row machine vision system},
  author={Gongal, A and Silwal, Abhisesh and Amatya, Suraj and Karkee, Manoj and Zhang, Q and Lewis, Karen},
  journal={Computers and Electronics in Agriculture},
  volume={120},
  pages={26--35},
  year={2016},
  publisher={Elsevier}}
@article{wang2017robust,
  title={A robust fruit image segmentation algorithm against varying illumination for vision system of fruit harvesting robot},
  author={Wang, Chenglin and Tang, Yunchao and Zou, Xiangjun and SiTu, Weiming and Feng, Wenxian},
  journal={Optik},
  volume={131},
  pages={626--631},
  year={2017},
  publisher={Elsevier}}
@article{lu2015detecting,
  title={Detecting citrus fruits and occlusion recovery under natural illumination conditions},
  author={Lu, Jun and Sang, Nong},
  journal={Computers and Electronics in Agriculture},
  volume={110},
  pages={121--130},
  year={2015},
  publisher={Elsevier}}
@article{lin2019guava,
  title={Guava detection and pose estimation using a low-cost RGB-D sensor in the field},
  author={Lin, Guichao and Tang, Yunchao and Zou, Xiangjun and Xiong, Juntao and Li, Jinhui},
  journal={Sensors},
  volume={19},
  number={2},
  pages={428},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}}
@article{juman2016novel,
  title={A novel tree trunk detection method for oil-palm plantation navigation},
  author={Juman, Mohammed Ayoub and Wong, Yee Wan and Rajkumar, Rajprasad Kumar and Goh, Lay Jian},
  journal={Computers and Electronics in Agriculture},
  volume={128},
  pages={172--180},
  year={2016},
  publisher={Elsevier}}
@inproceedings{changhui2017overlapped,
  title={Overlapped fruit recognition for citrus harvesting robot in natural scenes},
  author={Changhui, Yang and Youcheng, Hu and Lin, Huang and Sa, Liu and Yanping, Liu},
  booktitle={2017 2nd International Conference on Robotics and Automation Engineering (ICRAE)},
  pages={398--402},
  year={2017},
  organization={IEEE}}
@inproceedings{czuni2018color,
  title={Color Based Clustering for Trunk Segmentation},
  author={Cz{\'u}ni, L{\'a}szl{\'o} and K{\"u}rt{\"o}si, Andr{\'a}s and Alava, Karim Ben},
  booktitle={2018 25th International Conference on Systems, Signals and Image Processing (IWSSIP)},
  pages={1--4},
  year={2018},
  organization={IEEE}}
